{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mathildabineli/Moderation_model_mdeberta/blob/main/moderation_mdeberta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MbPMagDUbPK"
      },
      "outputs": [],
      "source": [
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!!pip install --upgrade tqdm"
      ],
      "metadata": {
        "id": "WjpTjZpN1CKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, math, json, re, numpy as np, pandas as pd\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from torch.utils.data import WeightedRandomSampler\n",
        "\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoConfig, AutoModel,\n",
        "    Trainer, TrainingArguments, DataCollatorWithPadding, EarlyStoppingCallback\n",
        ")\n",
        "from sklearn.metrics import f1_score, precision_recall_fscore_support\n"
      ],
      "metadata": {
        "id": "ZS2DSaT0kHde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "P3uMaHauUlMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "h0vKRy6NXKjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv('/content/gdrive/My Drive/tst-317/datasets_for_training/final_data.csv')"
      ],
      "metadata": {
        "id": "Bd6DMY9hWzfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(5)"
      ],
      "metadata": {
        "id": "GOXHk2KzXGy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info"
      ],
      "metadata": {
        "collapsed": true,
        "id": "3xveBfLzYWIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "\n",
        "def quick_moderation_report(\n",
        "    df: pd.DataFrame,\n",
        "    text_col: str = \"user_input\",\n",
        "    lang_col: str = \"language_code\",\n",
        "):\n",
        "    # 1) Identify candidate label columns = all 0/1-like numeric cols (exclude meta)\n",
        "    meta_cols = {text_col, lang_col, \"safe\", \"Unnamed: 0\", \"split\", \"id\"}\n",
        "    cand = [c for c in df.columns if c not in meta_cols]\n",
        "    label_cols = []\n",
        "    for c in cand:\n",
        "        s = df[c].dropna()\n",
        "        if pd.api.types.is_numeric_dtype(s) and s.isin([0, 1]).mean() > 0.98:\n",
        "            label_cols.append(c)\n",
        "\n",
        "    print(\"\\n=== SHAPE & MEMORY ===\")\n",
        "    print(\"shape:\", df.shape)\n",
        "    print(\"memory (MB):\", round(df.memory_usage(deep=True).sum() / 1e6, 2))\n",
        "\n",
        "    print(\"\\n=== DTYPES ===\")\n",
        "    print(df.dtypes)\n",
        "\n",
        "    print(\"\\n=== NULLS (top 20) ===\")\n",
        "    print(df.isna().sum().sort_values(ascending=False).head(20))\n",
        "\n",
        "    print(\"\\n=== LANGUAGES ===\")\n",
        "    print(df[lang_col].value_counts(dropna=False).head(30))\n",
        "\n",
        "    print(\"\\n=== REQUIRED LANGUAGE COVERAGE ===\")\n",
        "    required = {\"en\",\"fr\",\"de\",\"es\",\"pt\",\"it\",\"nl\",\"ar\",\"hi\",\"zh\"}\n",
        "    present = set(df[lang_col].astype(str).str.lower().unique())\n",
        "    print(\"present:\", sorted(list(present))[:20], \"â€¦\")\n",
        "    print(\"missing:\", sorted(list(required - present)))\n",
        "\n",
        "    print(\"\\n=== LABELS DETECTED ===\")\n",
        "    print(label_cols)\n",
        "\n",
        "    print(\"\\n=== POSITIVE COUNTS PER LABEL ===\")\n",
        "    pos_counts = df[label_cols].sum().sort_values(ascending=False)\n",
        "    print(pos_counts)\n",
        "\n",
        "    print(\"\\n=== PREVALENCE PER LABEL (%) ===\")\n",
        "    print((100 * pos_counts / len(df)).round(3))\n",
        "\n",
        "    print(\"\\n=== MULTI-LABEL CARDINALITY ===\")\n",
        "    lbl_card = df[label_cols].sum(axis=1)\n",
        "    print(\"avg labels/sample:\", lbl_card.mean().round(3))\n",
        "    print(\"label-count distribution:\\n\", lbl_card.value_counts().sort_index())\n",
        "\n",
        "    print(\"\\n=== PAIRWISE CO-OCCURRENCE (counts) ===\")\n",
        "    co = df[label_cols].T.dot(df[label_cols])  # counts of co-positives\n",
        "    print(co)\n",
        "\n",
        "    print(\"\\n=== PER-LANGUAGE PREVALENCE (%) ===\")\n",
        "    per_lang = (100 * df.groupby(lang_col)[label_cols].mean()).round(2)\n",
        "    print(per_lang.head(15))\n",
        "\n",
        "    print(\"\\n=== CONSISTENCY CHECKS ===\")\n",
        "    if \"safe\" in df.columns:\n",
        "        bad_safe = df[(df[label_cols].sum(axis=1) > 0) & (df[\"safe\"] == 1)]\n",
        "        print(\"safe==1 but some label==1:\", len(bad_safe))\n",
        "    if \"violence/graphic\" in df.columns and \"violence\" in df.columns:\n",
        "        vg_not_v = df[(df[\"violence/graphic\"] == 1) & (df[\"violence\"] != 1)]\n",
        "        print(\"violence/graphic==1 but violence!=1:\", len(vg_not_v))\n",
        "\n",
        "    print(\"\\n=== TEXT LENGTH (chars) ===\")\n",
        "    lens = df[text_col].astype(str).str.len()\n",
        "    print(lens.describe(percentiles=[.5, .9, .99]))\n",
        "\n",
        "    print(\"\\n=== URL / EMOJI FLAGS ===\")\n",
        "    url_pat = re.compile(r\"(https?://|www\\.)\", re.I)\n",
        "    emoji_pat = re.compile(r\"[\\U0001F300-\\U0001FAFF]\")\n",
        "    print(\"rows with URL:\", df[text_col].str.contains(url_pat, na=False).sum())\n",
        "    print(\"rows with emoji:\", df[text_col].str.contains(emoji_pat, na=False).sum())\n",
        "\n",
        "    print(\"\\n=== DUPLICATES ===\")\n",
        "    print(\"duplicate texts:\", df[text_col].duplicated(keep=False).sum())\n",
        "\n",
        "    # Return useful artifacts if you want to save them\n",
        "    return {\n",
        "        \"label_cols\": label_cols,\n",
        "        \"co_matrix\": co,\n",
        "        \"per_lang_prevalence\": per_lang,\n",
        "        \"pos_counts\": pos_counts\n",
        "    }\n",
        "\n",
        "# Example usage\n",
        "# df = pd.read_csv(\"PATH/TO/your_dataset.csv\")\n",
        "# report = quick_moderation_report(df)\n"
      ],
      "metadata": {
        "id": "YGdR1Ldde-mV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report = quick_moderation_report(data)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "XkSXVSm4fWbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.to_csv('data.csv')"
      ],
      "metadata": {
        "id": "RSO4wdGBl-XQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# 0) Config\n",
        "# -----------------------\n",
        "MODEL_NAME = os.getenv(\"MODEL_NAME\", \"microsoft/mdeberta-v3-base\")\n",
        "TEXT_COL = os.getenv(\"TEXT_COL\", \"user_input\")\n",
        "LANG_COL = os.getenv(\"LANG_COL\", \"language_code\")\n",
        "TRAIN_CSV = os.getenv(\"TRAIN_CSV\", \"data.csv\")\n",
        "OUTPUT_DIR = os.getenv(\"OUTPUT_DIR\", \"./outputs_teacher\")\n",
        "MAX_LEN = int(os.getenv(\"MAX_LEN\", \"256\"))\n",
        "LR = float(os.getenv(\"LR\", \"2e-5\"))\n",
        "EPOCHS = int(os.getenv(\"EPOCHS\", \"4\"))\n",
        "BATCH = int(os.getenv(\"BATCH\", \"16\"))\n",
        "SEED = int(os.getenv(\"SEED\", \"42\"))\n",
        "USE_LANG_HEAD = os.getenv(\"USE_LANG_HEAD\", \"true\").lower() == \"true\"\n",
        "LAMBDA_LANG = float(os.getenv(\"LAMBDA_LANG\", \"0.2\"))\n",
        "GAMMA_FOCAL = float(os.getenv(\"GAMMA_FOCAL\", \"2.0\"))\n",
        "\n",
        "# Optional: collapse toxicity/offensive\n",
        "MERGE_ABUSIVE = os.getenv(\"MERGE_ABUSIVE\", \"true\").lower() == \"true\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n"
      ],
      "metadata": {
        "id": "P5RcORBtkcX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# 1) Load & clean data\n",
        "# -----------------------\n",
        "rename_map = {\n",
        "    \"sexual/minors\": \"child_safety\",\n",
        "    \"violence/graphic\": \"violence_graphic\",\n",
        "    \"terrorist\": \"terrorism\",\n",
        "    LANG_COL: \"lang\",\n",
        "}\n",
        "df = data.rename(columns=rename_map)\n",
        "\n",
        "if MERGE_ABUSIVE and {\"toxicity\",\"offensive\"}.issubset(df.columns):\n",
        "    df[\"abusive\"] = df[[\"toxicity\",\"offensive\"]].max(axis=1)\n",
        "    df = df.drop(columns=[c for c in [\"toxicity\",\"offensive\"] if c in df.columns])\n",
        "\n",
        "# Constraint: graphic implies violence\n",
        "if {\"violence_graphic\",\"violence\"}.issubset(df.columns):\n",
        "    df.loc[df[\"violence_graphic\"]==1, \"violence\"] = 1\n",
        "\n",
        "# Hygiene\n",
        "df = df.dropna(subset=[TEXT_COL]).drop_duplicates(subset=[TEXT_COL])\n",
        "\n",
        "# Detect label columns (binary)\n",
        "meta_cols = {TEXT_COL, \"lang\", \"safe\", \"split\", \"id\"}\n",
        "label_cols = []\n",
        "for c in df.columns:\n",
        "    if c in meta_cols: continue\n",
        "    if pd.api.types.is_integer_dtype(df[c]) and set(df[c].unique()).issubset({0,1}):\n",
        "        label_cols.append(c)\n",
        "\n",
        "# Derive safe (not used as target)\n",
        "df[\"safe\"] = (df[label_cols].sum(axis=1) == 0).astype(int)\n",
        "\n",
        "# Language mapping\n",
        "langs = df[\"lang\"].astype(str).str.lower().fillna(\"unknown\").tolist()\n",
        "lang_vocab = sorted(list(dict.fromkeys(langs)))\n",
        "lang2id = {l:i for i,l in enumerate(lang_vocab)}\n",
        "df[\"lang_id\"] = [lang2id[l] for l in langs]\n",
        "\n",
        "# Train/val split (simple; replace with iterative stratification later)\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(\n",
        "    df, test_size=0.1, random_state=SEED, stratify=df[label_cols].sum(axis=1).clip(0,1)\n",
        ")\n",
        "\n",
        "print(\"Labels:\", label_cols)\n",
        "print(\"Languages:\", lang_vocab[:20], \"... (#\", len(lang_vocab), \")\")"
      ],
      "metadata": {
        "id": "y7JdNcLokdEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head(10)"
      ],
      "metadata": {
        "id": "HJzwI7QenTB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# 2) Tokenize\n",
        "# -----------------------\n",
        "tok = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "def preprocess(batch):\n",
        "    enc = tok(batch[TEXT_COL], truncation=True, padding=False, max_length=MAX_LEN)\n",
        "    # multi-label targets\n",
        "    labels = np.stack([batch[c] for c in label_cols], axis=1).astype(np.float32)\n",
        "    out = {**enc, \"labels\": labels}\n",
        "    if USE_LANG_HEAD:\n",
        "        out[\"lang_id\"] = batch[\"lang_id\"]\n",
        "    return out\n",
        "\n",
        "train_ds = Dataset.from_pandas(train_df, preserve_index=False).map(preprocess, batched=True, remove_columns=train_df.columns.to_list())\n",
        "val_ds   = Dataset.from_pandas(val_df,   preserve_index=False).map(preprocess, batched=True, remove_columns=val_df.columns.to_list())\n",
        "dset = DatasetDict(train=train_ds, validation=val_ds)"
      ],
      "metadata": {
        "id": "1U1YGymXmJT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoModel\n",
        "import numpy as np\n",
        "\n",
        "class MultiTaskDeberta(nn.Module):\n",
        "    def __init__(self, model_name, num_labels, num_langs, p_drop=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        #print(f\"Initializing model: {model_name}, with {num_labels} labels and {num_langs} languages.\")\n",
        "\n",
        "        self.backbone = AutoModel.from_pretrained(model_name)\n",
        "        hidden = self.backbone.config.hidden_size\n",
        "        self.dropout = nn.Dropout(p_drop)\n",
        "        self.cls = nn.Linear(hidden, num_labels)     # multi-label head\n",
        "        self.lang = nn.Linear(hidden, num_langs)     # language-ID head\n",
        "\n",
        "        self.use_lang_head = USE_LANG_HEAD\n",
        "\n",
        "        # Î± weights from prevalence\n",
        "        #print(\"Calculating class weights (alpha) based on label prevalence.\")\n",
        "        prev = train_df[label_cols].mean().values\n",
        "        alpha = 1.0 / np.clip(prev, 1e-4, 1.0)\n",
        "        alpha = alpha / alpha.max()  # Normalize alpha values\n",
        "        self.register_buffer(\"alpha\", torch.tensor(alpha, dtype=torch.float32))\n",
        "        self.gamma = GAMMA_FOCAL\n",
        "\n",
        "        print(f\"Model initialized with alpha weights: {self.alpha}, gamma: {self.gamma}\")\n",
        "\n",
        "    def focal_bce(self, logits, targets):\n",
        "        #print(\"Calculating focal loss.\")\n",
        "        # logits: [B, C], targets: [B, C] in {0,1}\n",
        "        bce = F.binary_cross_entropy_with_logits(logits, targets, reduction=\"none\")\n",
        "        p = torch.sigmoid(logits)\n",
        "        pt = p * targets + (1 - p) * (1 - targets)\n",
        "        mod = (1 - pt).pow(self.gamma)\n",
        "        loss = mod * bce\n",
        "        loss = loss * self.alpha  # Apply per-class weight\n",
        "        return loss.mean()\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, labels=None, lang_id=None):\n",
        "        #print(\"Forward pass: Extracting features.\")\n",
        "        out = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled = out.last_hidden_state[:, 0]  # CLS token\n",
        "        pooled = self.dropout(pooled)\n",
        "        logits = self.cls(pooled)\n",
        "        outputs = {\"logits\": logits}\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            #print(\"Calculating loss.\")\n",
        "            labels = labels.float()\n",
        "            loss = self.focal_bce(logits, labels)\n",
        "\n",
        "        if self.use_lang_head:\n",
        "            #print(\"Including language classification head.\")\n",
        "            lang_logits = self.lang(pooled)\n",
        "            outputs[\"lang_logits\"] = lang_logits\n",
        "            if lang_id is not None:\n",
        "                ce = F.cross_entropy(lang_logits, lang_id)\n",
        "                loss = loss + LAMBDA_LANG * ce if loss is not None else LAMBDA_LANG * ce\n",
        "\n",
        "        if loss is not None:\n",
        "            outputs[\"loss\"] = loss\n",
        "\n",
        "        return outputs\n",
        "\n",
        "# Initialize the model\n",
        "print(\"Initializing MultiTaskDeberta model...\")\n",
        "model = MultiTaskDeberta(MODEL_NAME, num_labels=len(label_cols), num_langs=len(lang_vocab))\n",
        "\n",
        "# Check the model's parameter count to ensure it's been initialized correctly\n",
        "num_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Model has {num_params / 1e6:.2f} million parameters.\")\n"
      ],
      "metadata": {
        "id": "bdncDiaCmvpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# 4) Metrics\n",
        "# -----------------------\n",
        "def sigmoid(x): return 1/(1+np.exp(-x))\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    # eval_pred can be ((logits, lang_logits), labels) depending on HF version\n",
        "    preds, labels = eval_pred\n",
        "    if isinstance(preds, tuple):  # (task_logits, lang_logits?)\n",
        "        preds = preds[0]\n",
        "    probs = sigmoid(preds)\n",
        "    # naive 0.5 threshold (we'll calibrate later)\n",
        "    y_pred = (probs >= 0.5).astype(int)\n",
        "    y_true = labels\n",
        "\n",
        "    macro_f1 = f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
        "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=None, zero_division=0)\n",
        "    return {\n",
        "        \"macro_f1\": macro_f1,\n",
        "        \"macro_recall\": rec.mean(),\n",
        "        \"macro_precision\": prec.mean(),\n",
        "    }"
      ],
      "metadata": {
        "id": "r-8x0NGWpQOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# 5) Weighted sampler (helps rare labels & low-resource langs)\n",
        "# -----------------------\n",
        "def make_weights(df: pd.DataFrame) -> np.ndarray:\n",
        "    # upweight positives and under-represented languages\n",
        "    pos = df[label_cols].sum(axis=1)\n",
        "    pos_w = 1 + 4*(pos > 0)\n",
        "    lang_counts = df[\"lang\"].value_counts()\n",
        "    lang_w = df[\"lang\"].map(lambda L: (lang_counts.max()/lang_counts[L])).astype(float)\n",
        "    return (pos_w * lang_w).values\n",
        "\n",
        "train_weights = make_weights(train_df)\n",
        "sampler = WeightedRandomSampler(train_weights, num_samples=len(train_weights), replacement=True)\n"
      ],
      "metadata": {
        "id": "xQh3JR7qrJK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# 6) Train\n",
        "# -----------------------\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tok)\n",
        "\n",
        "\n",
        "\n",
        "# Adjust the TrainingArguments for better GPU usage\n",
        "args = TrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    learning_rate=LR,\n",
        "    per_device_train_batch_size=BATCH,  # Train batch size\n",
        "    per_device_eval_batch_size=BATCH,  # Eval batch size\n",
        "    num_train_epochs=EPOCHS,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",  # How often to evaluate\n",
        "    save_strategy=\"epoch\",  # How often to save model\n",
        "    load_best_model_at_end=True,  # Ensure the best model is loaded at the end\n",
        "    metric_for_best_model=\"macro_f1\",\n",
        "    greater_is_better=True,\n",
        "    logging_steps=50,  # Log every 50 steps\n",
        "    logging_dir=OUTPUT_DIR,\n",
        "    fp16=True,  # Mixed precision training (if using a modern GPU)\n",
        "    report_to=\"none\",  # Disable external reporting (or set to \"tensorboard\" if needed)\n",
        "    seed=SEED,\n",
        "    gradient_accumulation_steps=2,  # Accumulate gradients to simulate larger batch sizes\n",
        "    dataloader_pin_memory=True,  # Pin memory for faster data loading\n",
        "    disable_tqdm=False,  # Enable tqdm progress bar\n",
        "    # Optionally, if you have multiple GPUs, enable this:\n",
        "    # _n_gpu=1,  # Uncomment if using multiple GPUs\n",
        "    # dataloader_num_workers=4  # You can increase the number of workers for faster data loading if needed\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "gHGinInCrNIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure model is on the correct device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "id": "FnbDajEQzfVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyTrainer(Trainer):\n",
        "    def get_train_dataloader(self):\n",
        "        print(\"Loading train dataloader...\")\n",
        "        dl = super().get_train_dataloader()\n",
        "        dl.sampler = sampler  # Use weighted sampler for imbalance\n",
        "        return dl\n",
        "\n",
        "\n",
        "trainer = MyTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=dset[\"train\"],\n",
        "    eval_dataset=dset[\"validation\"],\n",
        "    tokenizer=tok,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
        ")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "hrDTOQmosBYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_iterator = tqdm(trainer.get_train_dataloader(), desc=\"Training\", position=0, leave=True)\n",
        "eval_iterator = tqdm(trainer.get_eval_dataloader(), desc=\"Evaluating\", position=1, leave=True)\n"
      ],
      "metadata": {
        "id": "OaO4yX8K2FwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n",
        "\n",
        "# Save model and additional files\n",
        "trainer.save_model(OUTPUT_DIR)\n",
        "\n",
        "# Print a completion message\n",
        "print(f\"Training completed. Model saved in {OUTPUT_DIR}\")\n",
        "\n",
        "with open(os.path.join(OUTPUT_DIR, \"label_cols.json\"), \"w\") as f:\n",
        "    json.dump(label_cols, f, indent=2)\n",
        "with open(os.path.join(OUTPUT_DIR, \"lang_vocab.json\"), \"w\") as f:\n",
        "    json.dump(lang_vocab, f, indent=2)\n",
        "\n",
        "print(\"Training complete. Best metrics:\", trainer.state.best_metric)\n"
      ],
      "metadata": {
        "id": "w5DFZSjVuSkx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}